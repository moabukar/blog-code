apiVersion: batch/v1
kind: CronJob
metadata:
  name: rds-backup-cronjob
  namespace: default
spec:
  schedule: "0 2 * * *"   # Daily at 2 AM UTC
  timeZone: "UTC"
  concurrencyPolicy: Forbid
  failedJobsHistoryLimit: 3
  successfulJobsHistoryLimit: 3
  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: OnFailure
          containers:
            - name: rds-backup
              image: amazon/aws-cli:latest
              command:
                - /bin/bash
                - -c
                - |
                  set -euo pipefail
                  
                  echo "Starting streaming backup..."
                  
                  # Install PostgreSQL client
                  yum update -y -q
                  yum install -y -q postgresql15
                  
                  # Set up environment
                  export PGPASSWORD=$(cat /secrets/db-password)
                  export AWS_ACCESS_KEY_ID=$(cat /aws-secrets/aws-access-key-id)
                  export AWS_SECRET_ACCESS_KEY=$(cat /aws-secrets/aws-secret-access-key)
                  export AWS_DEFAULT_REGION="us-east-1"
                  
                  # For LocalStack testing - use host.docker.internal
                  export AWS_ENDPOINT_URL="http://host.docker.internal:4566"
                  
                  DB_HOST="postgres-replica-service.default.svc.cluster.local"
                  TIMESTAMP=$(date +%F-%H-%M)
                  S3_PATH="s3://rds-db-backups-co-create/$TIMESTAMP/backup.dump"
                  
                  echo "Target: $DB_HOST"
                  echo "S3 destination: $S3_PATH"
                  
                  # Verify database connection
                  pg_isready -h $DB_HOST -p 5432 -U root
                  
                  # Create and upload backup
                  START_TIME=$(date +%s)
                  pg_dump -h $DB_HOST -U root -p 5432 \
                    --format=custom \
                    --blobs \
                    --no-password \
                    langfuse | aws s3 cp - $S3_PATH --endpoint-url $AWS_ENDPOINT_URL
                  END_TIME=$(date +%s)
                  
                  DURATION=$((END_TIME - START_TIME))
                  echo "Backup completed in ${DURATION}s"
                  
                  # Verify upload
                  aws s3 ls $S3_PATH --endpoint-url $AWS_ENDPOINT_URL
                  echo "BACKUP SUCCESSFUL"
                  
                  unset PGPASSWORD
              volumeMounts:
                - name: db-secrets
                  mountPath: /secrets
                  readOnly: true
                - name: aws-secrets
                  mountPath: /aws-secrets
                  readOnly: true
              resources:
                requests:
                  memory: "512Mi"
                  cpu: "500m"
                limits:
                  memory: "1Gi"
                  cpu: "1000m"
          volumes:
            - name: db-secrets
              secret:
                secretName: rds-db-root-secret
            - name: aws-secrets
              secret:
                secretName: aws-credentials
